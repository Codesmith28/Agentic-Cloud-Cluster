# Task 4.6: GA Runner Implementation

## Overview

The **GA Runner** (`ga_runner.go`) orchestrates the complete genetic algorithm training cycle for the AOD (Affinity-based Online Dispatcher) system. It evolves populations of chromosomes to find optimal scheduling parameters by combining all previously implemented components: Theta Trainer, Affinity Builder, Penalty Builder, and Fitness Function.

---

## Architecture

### Component Integration

```
RunGAEpoch
    â”œâ”€â”€ Fetch Historical Data (HistoryDB)
    â”œâ”€â”€ Train Theta (Linear Regression) â†’ Task 4.2
    â”œâ”€â”€ Initialize Population (Random + Trained)
    â”œâ”€â”€ Evolutionary Loop (N generations)
    â”‚   â”œâ”€â”€ Evaluate Fitness â†’ Task 4.5
    â”‚   â”œâ”€â”€ Selection (Tournament)
    â”‚   â”œâ”€â”€ Crossover (Uniform)
    â”‚   â”œâ”€â”€ Mutation (Gaussian)
    â”‚   â””â”€â”€ Elitism (Preserve Best)
    â”œâ”€â”€ Build Affinity Matrix â†’ Task 4.3
    â”œâ”€â”€ Build Penalty Vector â†’ Task 4.4
    â””â”€â”€ Save GAParams (JSON)
```

---

## Core Components

### 1. Main Entry Point: `RunGAEpoch`

**Purpose**: Execute one complete GA training cycle and save optimized parameters.

**Signature**:
```go
func RunGAEpoch(
    ctx context.Context,
    historyDB *db.HistoryDB,
    config GAConfig,
    paramsOutputPath string,
) error
```

**Algorithm**:
1. **Data Collection** (Step 1-2):
   - Fetch last 24 hours of task history
   - Fetch last 24 hours of worker statistics
   - Validate sufficient data (minimum 10 tasks required)
   - If insufficient: save default parameters and exit

2. **Theta Training** (Step 3):
   - Use `TrainTheta()` to fit Î¸â‚, Î¸â‚‚, Î¸â‚ƒ, Î¸â‚„ via linear regression
   - These parameters predict execution time multipliers

3. **Population Initialization** (Step 4):
   - Create population of N chromosomes
   - First chromosome uses trained Theta + default weights
   - Remaining N-1 chromosomes randomly initialized

4. **Evolution** (Step 5):
   - For each generation (1 to G):
     - Evaluate fitness for all chromosomes
     - Log best/average/worst fitness
     - If last generation: stop
     - Otherwise:
       - Sort by fitness (best first)
       - Apply elitism (preserve top E chromosomes)
       - Fill remaining population via:
         - Tournament selection (pick 2 parents)
         - Uniform crossover (combine genes)
         - Gaussian mutation (add noise)
       - Validate offspring (discard invalid)

5. **Matrix Building** (Step 6-8):
   - Build affinity matrix using best chromosome's AffinityWeights
   - Build penalty vector using best chromosome's PenaltyWeights

6. **Persistence** (Step 9-10):
   - Package best parameters into `GAParams` struct
   - Save to JSON file (e.g., `config/ga_output.json`)
   - RTS scheduler hot-reloads this file every 30 seconds

**Example Output**:
```
ğŸ§¬ Starting GA epoch...
ğŸ“Š Fetching task history from 2025-11-16T04:00:00Z to 2025-11-17T04:00:00Z
ğŸ“Š Fetching worker stats from 2025-11-16T04:00:00Z to 2025-11-17T04:00:00Z
âœ“ Retrieved 142 task history records and 5 worker stats
ğŸ”§ Training Theta parameters using linear regression...
âœ“ Theta trained: Î¸â‚=0.1523, Î¸â‚‚=0.0987, Î¸â‚ƒ=0.2845, Î¸â‚„=0.2102
ğŸ§¬ Initializing population (size=20)
âœ“ Population initialized with 20 chromosomes
ğŸ§¬ Generation 1/10: Best=2.8456, Avg=2.1234, Worst=1.5678
ğŸ§¬ Generation 2/10: Best=2.9123, Avg=2.3456, Worst=1.8901
...
ğŸ§¬ Generation 10/10: Best=3.1234, Avg=2.8901, Worst=2.3456
ğŸ† Best chromosome fitness: 3.1234
ğŸ”§ Building affinity matrix from best chromosome...
âœ“ Affinity matrix built with 6 task types
ğŸ”§ Building penalty vector from best chromosome...
âœ“ Penalty vector built for 5 workers
âœ… GA epoch completed in 1.2345s, parameters saved to config/ga_output.json
```

---

### 2. Population Initialization: `initializePopulation`

**Purpose**: Create initial population with one trained chromosome + random variations.

**Algorithm**:
```go
func initializePopulation(config GAConfig, trainedTheta scheduler.Theta) Population {
    population := make(Population, 0, config.PopulationSize)
    
    // First chromosome: trained Theta + defaults
    base := Chromosome{
        Theta:     trainedTheta,           // From linear regression
        Risk:      defaultRisk(),          // Alpha=10.0, Beta=1.0
        AffinityW: defaultAffinityWeights(), // A1=1.0, A2=2.0, A3=0.5
        PenaltyW:  defaultPenaltyWeights(),  // G1=2.0, G2=1.0, G3=0.5
    }
    population = append(population, base)
    
    // Remaining chromosomes: random initialization
    for i := 1; i < config.PopulationSize; i++ {
        chromosome := Chromosome{
            Theta:     randomTheta(),           // [0, 0.5] for Î¸â‚, Î¸â‚‚
            Risk:      randomRisk(),            // Alpha [5, 20], Beta [0.5, 2.5]
            AffinityW: randomAffinityWeights(), // A1 [0.5, 2.5], A2 [1.0, 4.0]
            PenaltyW:  randomPenaltyWeights(),  // G1 [1.0, 4.0], G2 [0.5, 2.5]
        }
        population = append(population, chromosome)
    }
    
    return population
}
```

**Rationale**:
- **Exploitation**: Trained Theta seeds population with domain knowledge
- **Exploration**: Random chromosomes explore parameter space
- **Diversity**: Wide initialization ranges prevent premature convergence

---

### 3. Fitness Evaluation: `evaluatePopulation`

**Purpose**: Compute fitness for all chromosomes using Task 4.5 fitness function.

**Algorithm**:
```go
func evaluatePopulation(
    pop Population,
    history []db.TaskHistory,
    workerStats []db.WorkerStats,
    config GAConfig,
) Population {
    for i := 0; i < len(pop); i++ {
        // ComputeFitness from fitness.go (Task 4.5)
        pop[i].Fitness = ComputeFitness(pop[i], history, workerStats, config)
    }
    return pop
}
```

**Fitness Formula** (from Task 4.5):
```
Fitness = wâ‚Ã—SLA_success + wâ‚‚Ã—Utilization - wâ‚ƒÃ—Energy_norm - wâ‚„Ã—Overload_norm
```

Where default weights are: `[0.4, 0.3, 0.2, 0.1]`

---

### 4. Tournament Selection: `tournamentSelection`

**Purpose**: Select high-fitness individuals for reproduction.

**Algorithm**:
```go
func tournamentSelection(pop Population, tournamentSize int) Chromosome {
    // Handle edge cases
    k := min(tournamentSize, len(pop))
    
    // Pick k random candidates
    best := pop[rand.Intn(len(pop))]
    for i := 1; i < k; i++ {
        candidate := pop[rand.Intn(len(pop))]
        if candidate.Fitness > best.Fitness {
            best = candidate
        }
    }
    
    return best.Clone()
}
```

**Parameters**:
- **Tournament Size** (k=3): Number of candidates per tournament
- **Selection Pressure**: Larger k â†’ stronger pressure â†’ faster convergence but less diversity

**Rationale**:
- Simple and efficient (O(k))
- Maintains diversity better than roulette wheel
- No fitness scaling required

---

### 5. Uniform Crossover: `crossover`

**Purpose**: Combine two parent chromosomes to create offspring.

**Algorithm**:
```go
func crossover(parent1, parent2 Chromosome, crossoverRate float64) (Chromosome, Chromosome) {
    // Decide whether to crossover
    if rand.Float64() > crossoverRate {
        return parent1.Clone(), parent2.Clone()
    }
    
    child1, child2 := Chromosome{}, Chromosome{}
    
    // For each gene (Theta1, Theta2, ..., G3):
    //   50% chance: child1 gets parent1's gene, child2 gets parent2's
    //   50% chance: child1 gets parent2's gene, child2 gets parent1's
    
    // Example for Theta1:
    if rand.Float64() < 0.5 {
        child1.Theta.Theta1 = parent1.Theta.Theta1
        child2.Theta.Theta1 = parent2.Theta.Theta1
    } else {
        child1.Theta.Theta1 = parent2.Theta.Theta1
        child2.Theta.Theta1 = parent1.Theta.Theta1
    }
    // ... repeat for all 13 genes ...
    
    return child1, child2
}
```

**Genes** (13 total):
- Theta: Î¸â‚, Î¸â‚‚, Î¸â‚ƒ, Î¸â‚„ (4 genes)
- Risk: Î±, Î² (2 genes)
- AffinityWeights: aâ‚, aâ‚‚, aâ‚ƒ (3 genes)
- PenaltyWeights: gâ‚, gâ‚‚, gâ‚ƒ (4 genes)

**Crossover Rate**: 0.7 (70% of couples produce mixed offspring)

**Rationale**:
- Uniform crossover preserves genetic diversity better than single-point
- Independent gene inheritance explores more combinations

---

### 6. Gaussian Mutation: `mutate`

**Purpose**: Introduce random variations to prevent local optima.

**Algorithm**:
```go
func mutate(c Chromosome, mutationRate float64) Chromosome {
    mutant := c.Clone()
    
    // For each gene:
    if rand.Float64() < mutationRate {
        // Add Gaussian noise N(0, ÏƒÂ²)
        mutant.Theta.Theta1 += rand.NormFloat64() * 0.1
        // Clip to valid range [0.0, 2.0]
        mutant.Theta.Theta1 = max(0.0, min(2.0, mutant.Theta.Theta1))
    }
    // ... repeat for all genes ...
    
    return mutant
}
```

**Mutation Rate**: 0.1 (10% per gene)

**Standard Deviations**:
- Theta: Ïƒ=0.1 (small adjustments to trained values)
- Risk: Ïƒ=2.0 for Alpha, Ïƒ=0.5 for Beta
- Affinity/Penalty Weights: Ïƒ=0.2

**Bounds Enforcement**:
- Theta: [0.0, 2.0]
- Risk Alpha: [0.1, 100.0]
- Risk Beta: [0.1, 100.0]
- AffinityWeights: A1, A2 âˆˆ [0.1, 10.0], A3 âˆˆ [0.0, 10.0]
- PenaltyWeights: [0.0, 10.0]

**Rationale**:
- Gaussian mutation (vs uniform) produces small, realistic changes
- Clipping ensures chromosomes remain valid
- Low mutation rate balances exploration vs exploitation

---

### 7. Elitism

**Purpose**: Preserve best solutions across generations.

**Implementation**:
```go
// Sort population by fitness (descending)
sort.Sort(population)

// Preserve top E chromosomes unchanged
for i := 0; i < config.ElitismCount && i < len(population); i++ {
    nextGen = append(nextGen, population[i].Clone())
}
```

**Elitism Count**: 2 (preserve top 2 chromosomes)

**Rationale**:
- Guarantees best fitness never decreases (monotonic improvement)
- Prevents accidental loss of good solutions
- Small elite size (2/20 = 10%) maintains diversity

---

## Configuration

### GAConfig Parameters

```go
type GAConfig struct {
    PopulationSize int       // Default: 20
    Generations    int       // Default: 10
    MutationRate   float64   // Default: 0.1 (10%)
    CrossoverRate  float64   // Default: 0.7 (70%)
    FitnessWeights [4]float64 // Default: [0.4, 0.3, 0.2, 0.1]
    ElitismCount   int       // Default: 2
    TournamentSize int       // Default: 3
}
```

### Default Values

**Chromosome Defaults**:
```go
Theta:     {Theta1: 0.1, Theta2: 0.1, Theta3: 0.3, Theta4: 0.2}
Risk:      {Alpha: 10.0, Beta: 1.0}
AffinityW: {A1: 1.0, A2: 2.0, A3: 0.5}
PenaltyW:  {G1: 2.0, G2: 1.0, G3: 0.5}
```

**Random Initialization Ranges**:
```go
Theta1, Theta2: [0.0, 0.5]
Theta3:         [0.0, 0.8]
Theta4:         [0.0, 0.6]
Alpha:          [5.0, 20.0]
Beta:           [0.5, 2.5]
A1:             [0.5, 2.5]
A2:             [1.0, 4.0]
A3:             [0.0, 1.5]
G1:             [1.0, 4.0]
G2, G3:         [0.5, 2.5] / [0.0, 1.5]
```

---

## Testing

### Test Coverage (14 tests, 119 total including subtests)

1. **TestInitializePopulation**: Verifies population size and first chromosome uses trained Theta
2. **TestEvaluatePopulation**: Confirms all chromosomes get non-zero fitness
3. **TestTournamentSelection**: Validates high-fitness individuals selected more often
4. **TestTournamentSelectionEdgeCases**: Empty population, single chromosome, large tournament size
5. **TestCrossover**: Verifies uniform crossover logic and 0% rate produces clones
6. **TestMutate**: Confirms mutation changes genes and preserves validity
7. **TestMutationBounds**: Ensures mutation respects parameter bounds (100 iterations)
8. **TestSaveGAParams**: Validates JSON serialization/deserialization
9. **TestSaveDefaultParams**: Tests fallback when data insufficient
10. **TestDefaultHelpers**: Checks default value generation
11. **TestRandomHelpers**: Validates random initialization ranges (100 iterations)

### Mock Data Generators

```go
func generateMockTaskHistory(count int) []db.TaskHistory
func generateMockWorkerStats(count int) []db.WorkerStats
```

Generate realistic test data with:
- 6 task types (cpu-light, cpu-heavy, memory-heavy, gpu-inference, gpu-training, mixed)
- 3 workers with varying performance
- 80-120% runtime variance around tau
- SLA success/failure based on deadlines

---

## Performance Characteristics

### Computational Complexity

- **Population Init**: O(N) where N = PopulationSize
- **Fitness Evaluation**: O(N Ã— M) where M = TaskHistory size
- **Selection**: O(k Ã— G Ã— N) where k = TournamentSize, G = Generations
- **Crossover**: O(G Ã— N)
- **Mutation**: O(G Ã— N)
- **Total**: O(G Ã— N Ã— M) â‰ˆ O(Generations Ã— PopulationSize Ã— HistorySize)

### Typical Runtime

With default config (N=20, G=10, M=100):
- **CPU Time**: ~0.5-2.0 seconds
- **Memory**: ~10-50 MB (depends on history size)

### Scalability

- **Small System**: N=10, G=5 â†’ ~0.2s
- **Medium System**: N=20, G=10 â†’ ~1.0s
- **Large System**: N=50, G=20 â†’ ~5.0s

---

## Integration with RTS

### Epoch Scheduling (Task 4.7)

```go
// In main.go
go func() {
    ticker := time.NewTicker(60 * time.Second) // Run every 60 seconds
    defer ticker.Stop()
    for range ticker.C {
        if err := aod.RunGAEpoch(ctx, historyDB, gaConfig, "config/ga_output.json"); err != nil {
            log.Printf("AOD/GA epoch error: %v", err)
        }
    }
}()
```

### Parameter Hot-Reloading

```go
// In rts_scheduler.go
func (s *RTSScheduler) startParamsReloader() {
    go func() {
        ticker := time.NewTicker(30 * time.Second) // Reload every 30 seconds
        for range ticker.C {
            if params, err := LoadGAParams(s.paramsPath); err == nil {
                s.paramsMu.Lock()
                s.params = params
                s.paramsMu.Unlock()
            }
        }
    }()
}
```

### Data Flow

```
Task Execution â†’ Task History DB
                      â†“
                GA Epoch (every 60s)
                      â†“
                ga_output.json
                      â†“
                RTS Hot-Reload (every 30s)
                      â†“
                Updated Scheduling Decisions
```

---

## Key Design Decisions

### 1. Why Uniform Crossover?

**Alternatives Considered**:
- Single-point crossover
- Two-point crossover
- Arithmetic crossover

**Chosen**: Uniform crossover

**Rationale**:
- Better exploration of parameter space
- No bias toward gene position
- Works well with heterogeneous genes (Theta, Risk, Weights)

### 2. Why Tournament Selection?

**Alternatives Considered**:
- Roulette wheel selection
- Rank-based selection
- Stochastic universal sampling

**Chosen**: Tournament selection (k=3)

**Rationale**:
- No fitness scaling required
- Easy to parallelize
- Adjustable selection pressure via tournament size
- Robust to negative fitness values

### 3. Why Gaussian Mutation?

**Alternatives Considered**:
- Uniform mutation
- Polynomial mutation
- Adaptive mutation

**Chosen**: Gaussian mutation with fixed Ïƒ

**Rationale**:
- Small, realistic parameter adjustments
- Rare large jumps for exploration
- Well-understood statistical properties

### 4. Why 20/10 (Population/Generations)?

**Alternatives Considered**:
- Small: 10/5 (faster, less accurate)
- Large: 50/20 (slower, potentially better convergence)

**Chosen**: 20/10

**Rationale**:
- Balances runtime (~1s) with solution quality
- Sufficient diversity (20 chromosomes)
- Converges within 10 generations on typical workloads
- Can run every 60s without blocking

---

## Future Enhancements

### 1. Adaptive Parameters

**Current**: Fixed mutation/crossover rates

**Proposed**:
```go
mutationRate = max(0.05, 0.2 * (1 - generation/maxGenerations))
```

Decrease mutation rate as evolution progresses (exploitation phase).

### 2. Multi-Objective Optimization

**Current**: Single fitness value (weighted sum)

**Proposed**: Pareto frontier with NSGA-II
- SLA compliance (maximize)
- Resource utilization (maximize)
- Energy consumption (minimize)
- Overload frequency (minimize)

### 3. Island Model (Parallel GA)

**Current**: Single population

**Proposed**: Multiple sub-populations with periodic migration
- Exploit multiple CPU cores
- Better diversity maintenance
- Faster convergence on large datasets

### 4. Surrogate-Assisted Fitness

**Current**: Evaluate every chromosome on full history

**Proposed**: Train surrogate model (neural network) to predict fitness
- Faster fitness evaluation (~100x speedup)
- Allows larger populations (N=100+)

---

## Troubleshooting

### Issue 1: GA Not Converging

**Symptoms**: Best fitness stagnant or decreasing

**Possible Causes**:
- Insufficient data (< 10 tasks)
- Poor fitness weight selection
- Mutation rate too high (destroying good solutions)
- Population size too small

**Solutions**:
- Increase history window (24h â†’ 48h)
- Tune fitness weights for your workload
- Decrease mutation rate (0.1 â†’ 0.05)
- Increase population size (20 â†’ 50)

### Issue 2: Runtime Too Slow

**Symptoms**: GA epoch > 5 seconds

**Possible Causes**:
- Large history size (> 1000 tasks)
- Large population (> 50)
- Too many generations (> 20)

**Solutions**:
- Sample history (use last 500 tasks)
- Reduce population size (20 â†’ 10)
- Reduce generations (10 â†’ 5)
- Run GA less frequently (60s â†’ 120s)

### Issue 3: Invalid Chromosomes

**Symptoms**: "Chromosome is invalid" errors

**Possible Causes**:
- Mutation producing out-of-bound values
- Crossover creating invalid combinations

**Solutions**:
- Check mutation clipping logic
- Add validation after crossover
- Increase initial population diversity

---

## File Structure

```
master/internal/aod/
â”œâ”€â”€ models.go              # Chromosome, Population, GAConfig (Task 4.1)
â”œâ”€â”€ theta_trainer.go       # TrainTheta (Task 4.2)
â”œâ”€â”€ affinity_builder.go    # BuildAffinityMatrix (Task 4.3)
â”œâ”€â”€ penalty_builder.go     # BuildPenaltyVector (Task 4.4)
â”œâ”€â”€ fitness.go             # ComputeFitness (Task 4.5)
â”œâ”€â”€ ga_runner.go           # RunGAEpoch â† THIS FILE
â””â”€â”€ ga_runner_test.go      # 14 tests for GA operators
```

---

## Summary

Task 4.6 implements the **complete genetic algorithm** that:

1. âœ… Fetches historical data from database
2. âœ… Trains Theta using linear regression (Task 4.2)
3. âœ… Initializes population with trained + random chromosomes
4. âœ… Evolves population over multiple generations:
   - Tournament selection
   - Uniform crossover
   - Gaussian mutation
   - Elitism preservation
5. âœ… Builds affinity matrix (Task 4.3) and penalty vector (Task 4.4)
6. âœ… Evaluates fitness (Task 4.5) to guide evolution
7. âœ… Saves optimized parameters to JSON for RTS hot-reload

**Test Results**: 119/119 tests passing (14 new GA tests + 105 from previous tasks)

**Next Step**: Task 4.7 - Integrate AOD into Master (add GA epoch ticker in main.go)

---

## References

- **Sprint Plan**: See `SPRINT_PLAN.md` Task 4.6
- **Related Tasks**:
  - Task 4.1: AOD Data Models
  - Task 4.2: Theta Trainer
  - Task 4.3: Affinity Builder
  - Task 4.4: Penalty Builder
  - Task 4.5: Fitness Function
  - Task 4.7: Master Integration (next)

- **Genetic Algorithm Theory**:
  - Goldberg, D.E. (1989). "Genetic Algorithms in Search, Optimization, and Machine Learning"
  - Deb, K. (2001). "Multi-Objective Optimization using Evolutionary Algorithms"

- **Implementation Details**:
  - Tournament Selection: Miller & Goldberg (1995)
  - Uniform Crossover: Syswerda (1989)
  - Elitism: De Jong (1975)
